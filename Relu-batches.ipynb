{
 "metadata": {
  "name": "",
  "signature": "sha256:038ac091ddd1c173cffdde7975d2c5b6e6d036843cf5e5903b0e8d3d7d87d338"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math, string, random, itertools, copy\n",
      "import numpy as np\n",
      "from numpy import float32\n",
      "from math import sqrt\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.stats import poisson\n",
      "from copy        import deepcopy\n",
      "import time\n",
      "import theanets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Couldn't import dot_parser, loading of dot files will not be possible.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import h5py\n",
      "f=h5py.File(\"data/data2M.hdf5\")\n",
      "f.keys()\n",
      "f['data'].keys()\n",
      "\n",
      "# Load Data \n",
      "input_matrix     = f['data']['input'].value\n",
      "target_matrix    = f['data']['target'].value\n",
      "decorator_matrix = f['data']['deco'].value\n",
      "\n",
      "print \"Samples in input_matrix=\", len(input_matrix)\n",
      "\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetTrainBatch(batch_size):\n",
      "    \n",
      "    TrainingCut= int(input_matrix.shape[0]*0.8)\n",
      "    \n",
      "    # -------------------------------------------------------------------------------\n",
      "    # -    Training Set   -> [0, TrainingCut]  \n",
      "    # -    Validation Set -> [TrainingCut, len(input_matrix)]     -> Batch size is <1000> for both, Train Batch and Valid Batch. \n",
      "    # -------------------------------------------------------------------------------\n",
      "    # Training Batch => Collect randomly <batch_size> samples from the training set.\n",
      "\n",
      "    cut_from    = random.randrange(TrainingCut - batch_size)  \n",
      "    cut_to      = cut_from + batch_size\n",
      "    train_batch = input_matrix[cut_from:cut_to], target_matrix[cut_from:cut_to]\n",
      "    \n",
      "    print \"Training Batch:   [\",cut_from, \",\", cut_to, \"]\", \" size=\", len(train_batch[0])\n",
      "    \n",
      "    return train_batch\n",
      "\n",
      "def GetValidBatch(batch_size):\n",
      "    TrainingCut= int(input_matrix.shape[0]*0.8)\n",
      "    # --------------------------------------------------------------------------------\n",
      "    # Validation Batch => Collect randomly <batch_size> samples from the validation set\n",
      "\n",
      "    cut_from    = random.randrange(TrainingCut, len(input_matrix)-batch_size)\n",
      "    cut_to      = cut_from + batch_size\n",
      "    valid_batch = input_matrix[cut_from:cut_to], target_matrix[cut_from:cut_to]\n",
      "\n",
      "    print \"Validation Batch: [\",cut_from, \",\", cut_to, \"]\", \"size=\", len(valid_batch[0])\n",
      "    return valid_batch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nInputs  = input_matrix.shape[1]\n",
      "nOutputs = target_matrix.shape[1]\n",
      "\n",
      "print \" Inputs=\", nInputs, \"       Outputs=\",nOutputs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Inputs= 82        Outputs= 1\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def GetTrainBatch(train,batch_size):       \n",
      "#    cut_from = random.randrange(len(train[0])-batch_size)    \n",
      "#    train_batch = train[0][cut_from:cut_from+batch_size],train[1][cut_from:cut_from+batch_size]\n",
      "#    print \"Training Batch: from \",cut_from, \" to \", cut_from+batch_size\n",
      "#    return train_batch\n",
      "\n",
      "# def GetValidBatch(valid,batch_size):  \n",
      "#    cut_from = random.randrange(len(valid[0])-batch_size)\n",
      "#    valid_batch = valid[0][cut_from:cut_from+batch_size],valid[1][cut_from:cut_from+batch_size]\n",
      "#    print \"Validation Batch: from \", cut_from, \" to \", cut_from+batch_size\n",
      "#    return  valid_batch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def allincluded(truncated, nHiddenLayers, nHiddenNeurons):\n",
      "\n",
      "    # Build the NN\n",
      "    # -----------------------------------------------------------------------------------------------------------------------------------\n",
      "    # Topology: Feedforward\n",
      "    # Inputs = 82 (Jets 4-momenta (20 Jets maximum), METx, METy)\n",
      "    # Number of Hidden Layers = nHiddenLayers\n",
      "    # Activation function for Hidden Layers = RELU\n",
      "    # Outputs=1 (NN Trigger Bits= 0 or 1)\n",
      "    # Activation function for the Output Layer= RELU\n",
      "\n",
      "    exp=theanets.Experiment(theanets.feedforward.Regressor(layers=(nInputs,)+tuple([nHiddenNeurons for l in range(nHiddenLayers)])+ ( (nOutputs),)))  \n",
      "    # ------------------------------------------------------------------------------------------------------------------------------------\n",
      "    \n",
      "    fom   = 1.0\n",
      "    LearningRate=0.001\n",
      "    Epochs= 0\n",
      "    batch_size=2000\n",
      "    \n",
      "    timing_start = time.mktime(time.gmtime())\n",
      "    for TrainError, ValError in exp.itertrain(GetTrainBatch(batch_size),\n",
      "                                              GetValidBatch(batch_size),\n",
      "                                              learning_rate      = LearningRate, \n",
      "                                              algo               ='rprop', \n",
      "                                              hidden_dropout     = 0.9, \n",
      "                                              batch_size         = batch_size, \n",
      "                                              validate_every     = 1,\n",
      "                                              iteration_size     = 200,\n",
      "                                              patience           = 300, \n",
      "                                              min_improvement    = 0.0000001,\n",
      "                                              rms_halflife       = 0.995, \n",
      "                                              rms_regularizer    = 1e-09):\n",
      "      \n",
      "        print 'Epoch=', Epochs+1\n",
      "        if Epochs%1 == 0 :\n",
      "            print 'Training   Error = \\t',TrainError['err']\n",
      "            print 'Validation Error = \\t',ValError['err']\n",
      "        Epochs+=1\n",
      "        if Epochs == 10 :\n",
      "            break\n",
      "    \n",
      "    timing_end=time.mktime(time.gmtime())\n",
      "    \n",
      "    #prediction = exp.network.predict(train[0])\n",
      "    #goodness = np.asarray([[cut,(list(train[1][np.where(prediction>cut)]==1).count(True)+list(train[1][np.where(prediction<cut)]==0).count(True))/ float(train[0].shape[0])]  for cut in np.arange(0,1,0.05)])   \n",
      "    #fom_train = max( goodness[:,1])    \n",
      "    \n",
      "    #prediction = exp.network.predict(valid[0])\n",
      "    #goodness   = np.asarray([[cut,(list(valid[1][np.where(prediction>cut)]==1).count(True)+list(valid[1][np.where(prediction<cut)]==0).count(True))/ float(valid[0].shape[0])]  for cut in np.arange(0,1,0.05)])\n",
      "    #fom_valid  = max( goodness[:,1])     \n",
      "\n",
      "    #MaxCut= goodness[np.where(goodness[:,1]==goodness[:,1].max())][0][0]\n",
      "\n",
      "    #timing=timing_end-timing_start\n",
      "    \n",
      "    #exp.save('network-pickle.pkl.gz')\n",
      "    MaxCut=0\n",
      "    timing=0\n",
      "    \n",
      "    return fom_valid, fom_train, MaxCut,timing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapAlgo=[]\n",
      "\n",
      "for iLayers in range(1,11):\n",
      "    print \"--------------------- iLayers = \",iLayers, \"--------------------------------------\"\n",
      "    for nHiddenNeurons in range(800, 2000, 200):\n",
      "        print \"   Hidden Neurons=\", nHiddenNeurons\n",
      "        for truncate in range(800000,1800000,200000):\n",
      "            print \"   Samples=\",truncate\n",
      "            fom_valid, fom_train, MaxCut, timing = allincluded(truncate, iLayers, nHiddenNeurons)\n",
      "            mapAlgo.append((truncate, iLayers, nHiddenNeurons, timing, fom_valid, fom_train, MaxCut))\n",
      "            print  \"   F.O.M. valid=\",fom_valid, \"FOM train=\", fom_train, \"  Time=\", timing, ' MaxCut=',MaxCut "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------- iLayers =  1 --------------------------------------\n",
        "   Hidden Neurons= 800\n",
        "   Samples= 800000\n",
        "Training Batch:   [ 1036052 , 1038052 ]  size= 2000\n",
        "Validation Batch: [ 1735119 , 1737119 ] size= 2000\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training   Error = \t0.280793040691\n",
        "Validation Error = \t4.00001563877\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training   Error = \t0.100681755965\n",
        "Validation Error = \t0.231151302146\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training   Error = \t0.0374850845049\n",
        "Validation Error = \t0.18194998524\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training   Error = \t0.0107024317338\n",
        "Validation Error = \t0.170197245086\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training   Error = \t0.00227763365453\n",
        "Validation Error = \t0.168562419923\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training   Error = \t0.000492022437053\n",
        "Validation Error = \t0.168980833904\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training   Error = \t0.000107225401824\n",
        "Validation Error = \t0.170064998889\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "Training   Error = \t1.25922622684e-05\n",
        "Validation Error = \t0.170098453868\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Training   Error = \t5.59504568231e-07\n",
        "Validation Error = \t0.170565551975\n",
        "Epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Training   Error = \t3.43291346302e-08\n",
        "Validation Error = \t0.170735855006\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "global name 'fom_valid' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-20-0ffc80d64932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtruncate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m800000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1800000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"   Samples=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mfom_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfom_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxCut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallincluded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miLayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnHiddenNeurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mmapAlgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miLayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnHiddenNeurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiming\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfom_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfom_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxCut\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mprint\u001b[0m  \u001b[1;34m\"   F.O.M. valid=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfom_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FOM train=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfom_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"  Time=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiming\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' MaxCut='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMaxCut\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-19-540a67b5e77b>\u001b[0m in \u001b[0;36mallincluded\u001b[1;34m(truncated, nHiddenLayers, nHiddenNeurons)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mtiming\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfom_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfom_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxCut\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtiming\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: global name 'fom_valid' is not defined"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mapAlgo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}