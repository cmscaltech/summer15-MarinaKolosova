{
 "metadata": {
  "name": "",
  "signature": "sha256:f34fe2a4b1eba26d124ad8201990d2be534da4287af80112d21437abf9a48807"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import h5py\n",
      "import theanets\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Couldn't import dot_parser, loading of dot files will not be possible.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f=h5py.File(\"data/data.hdf5\")\n",
      "f.keys()\n",
      "f['data'].keys()\n",
      "input_matrix     = f['data']['input'].value\n",
      "target_matrix    = f['data']['target'].value\n",
      "decorator_matrix = f['data']['deco'].value\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nInputs = input_matrix.shape[1]\n",
      "nOutputs = target_matrix.shape[1]\n",
      "\n",
      "truncate=10000\n",
      "\n",
      "nInputs = input_matrix.shape[1]\n",
      "nOutputs = target_matrix.shape[1]\n",
      "\n",
      "input_matrix = input_matrix[0:truncate,...]\n",
      "target_matrix = target_matrix[0:truncate,...]\n",
      "decorator_matrix = decorator_matrix[0:truncate,...]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def allincluded( truncated, nHiddenLayers, epochs, trainings,HiddenNeurons):\n",
      "    timing_start = time.mktime(time.gmtime())\n",
      "    fom = 1.0\n",
      "    \n",
      "    exp=theanets.Experiment(theanets.feedforward.Regressor(layers=(nInputs,)+tuple([HiddenNeurons for l in range(nHiddenLayers)])+ ( (nOutputs, 'sigmoid'),)),'layerwise')    \n",
      "        \n",
      "    cut   =int(input_matrix.shape[0]*0.8)\n",
      "    train =input_matrix[:cut], target_matrix[:cut]\n",
      "    valid =input_matrix[cut:], target_matrix[cut:]\n",
      "    \n",
      "    for i in range(0, epochs):\n",
      "        for j in range(trainings):\n",
      "            exp.train(train, valid, learning_rate=0.1/10**i, batch_size=100)        \n",
      "    timing_end=time.mktime(time.gmtime())\n",
      "    \n",
      "    prediction = exp.network.predict(train[0])\n",
      "    goodness = np.asarray([[cut,(list(target_matrix[np.where(prediction>cut)]==1).count(True)+list(target_matrix[np.where(prediction<cut)]==0).count(True))/ float(input_matrix.shape[0])]  for cut in np.arange(0,1,0.05)])\n",
      "    fom = max( goodness[:,1])\n",
      "    \n",
      "    timing=timing_end-timing_start\n",
      "    return (fom, timing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# (Number of Samples, Hidden Layers, Epoch, Trainings, Timing, FOM, Hidden Neurons) \n",
      "mapAlgo=[]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mapAlgo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iLayers=1\n",
      "HiddenNeurons=100\n",
      "trainings=2\n",
      "epochs=10\n",
      "\n",
      "for nHN in range(10):\n",
      "    truncate=10000\n",
      "    for j in range (0, 5):\n",
      "        input_matrix     = input_matrix[0:truncate,...]\n",
      "        target_matrix    = target_matrix[0:truncate,...]\n",
      "        decorator_matrix = decorator_matrix[0:truncate,...]\n",
      "        \n",
      "        fom, timing = allincluded(truncate,iLayers,epochs,trainings,HiddenNeurons)\n",
      "        mapAlgo.append((truncate,iLayers,epochs,trainings,timing,fom,HiddenNeurons))\n",
      "        print 'Samples=',truncate,'Hidden Layers=',iLayers, 'epochs=', epochs, 'trainings=', trainings, \"fom=\",fom,\" time=\", timing, 'Hidden Neurons=',HiddenNeurons \n",
      "        truncate+=10000\n",
      "    HiddenNeurons+=100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mapAlgo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(10000, 1, 10, 2, 207.0, 0.76270000000000004, 100), (20000, 1, 10, 2, 276.0, 0.47420000000000001, 100), (30000, 1, 10, 2, 202.0, 0.77170000000000005, 100), (40000, 1, 10, 2, 204.0, 0.77590000000000003, 100), (50000, 1, 10, 2, 202.0, 0.79110000000000003, 100), (10000, 1, 10, 2, 356.0, 0.77359999999999995, 200), (20000, 1, 10, 2, 351.0, 0.78649999999999998, 200), (30000, 1, 10, 2, 355.0, 0.78690000000000004, 200), (40000, 1, 10, 2, 367.0, 0.78239999999999998, 200), (50000, 1, 10, 2, 360.0, 0.78559999999999997, 200), (10000, 1, 10, 2, 520.0, 0.79369999999999996, 300), (20000, 1, 10, 2, 518.0, 0.78939999999999999, 300), (30000, 1, 10, 2, 499.0, 0.78659999999999997, 300), (40000, 1, 10, 2, 518.0, 0.78800000000000003, 300), (50000, 1, 10, 2, 509.0, 0.78759999999999997, 300), (10000, 1, 10, 2, 797.0, 0.78129999999999999, 400), (20000, 1, 10, 2, 657.0, 0.78390000000000004, 400), (30000, 1, 10, 2, 671.0, 0.78400000000000003, 400), (40000, 1, 10, 2, 685.0, 0.78749999999999998, 400), (50000, 1, 10, 2, 706.0, 0.79730000000000001, 400), (10000, 1, 10, 2, 799.0, 0.77729999999999999, 500), (20000, 1, 10, 2, 960.0, 0.47420000000000001, 500), (30000, 1, 10, 2, 822.0, 0.77039999999999997, 500), (40000, 1, 10, 2, 870.0, 0.78590000000000004, 500), (50000, 1, 10, 2, 938.0, 0.47420000000000001, 500), (10000, 1, 10, 2, 947.0, 0.78739999999999999, 600), (20000, 1, 10, 2, 952.0, 0.76119999999999999, 600), (30000, 1, 10, 2, 929.0, 0.78510000000000002, 600), (40000, 1, 10, 2, 943.0, 0.7964, 600), (50000, 1, 10, 2, 994.0, 0.77100000000000002, 600), (10000, 1, 10, 2, 1183.0, 0.7893, 700), (20000, 1, 10, 2, 1199.0, 0.79379999999999995, 700), (30000, 1, 10, 2, 1175.0, 0.78969999999999996, 700), (40000, 1, 10, 2, 1170.0, 0.78979999999999995, 700), (50000, 1, 10, 2, 1211.0, 0.78920000000000001, 700), (10000, 1, 10, 2, 1414.0, 0.78280000000000005, 800), (20000, 1, 10, 2, 1366.0, 0.78700000000000003, 800), (30000, 1, 10, 2, 1296.0, 0.79120000000000001, 800), (40000, 1, 10, 2, 1350.0, 0.78569999999999995, 800), (50000, 1, 10, 2, 1348.0, 0.79690000000000005, 800), (10000, 1, 10, 2, 1519.0, 0.77229999999999999, 900), (20000, 1, 10, 2, 1637.0, 0.78890000000000005, 900), (30000, 1, 10, 2, 1465.0, 0.77859999999999996, 900), (40000, 1, 10, 2, 1470.0, 0.79010000000000002, 900), (50000, 1, 10, 2, 1520.0, 0.78910000000000002, 900), (10000, 1, 10, 2, 1669.0, 0.79479999999999995, 1000), (20000, 1, 10, 2, 1650.0, 0.78979999999999995, 1000), (30000, 1, 10, 2, 1653.0, 0.7792, 1000), (40000, 1, 10, 2, 1654.0, 0.79420000000000002, 1000), (50000, 1, 10, 2, 1649.0, 0.78910000000000002, 1000)]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter([x[0] for x in mapAlgo], [y[5] for y in mapAlgo])\n",
      "plt.xlabel('Number of Samples')\n",
      "plt.ylabel('FOM')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<matplotlib.text.Text at 0x7fd799f604d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fd7b772fc50>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iLayers=2\n",
      "HiddenNeurons=100\n",
      "trainings=2\n",
      "epochs=10\n",
      "\n",
      "for nHN in range(10):\n",
      "    truncate=10000\n",
      "    for j in range (0, 5):\n",
      "        input_matrix     = input_matrix[0:truncate,...]\n",
      "        target_matrix    = target_matrix[0:truncate,...]\n",
      "        decorator_matrix = decorator_matrix[0:truncate,...]\n",
      "        \n",
      "        fom, timing = allincluded(truncate,iLayers,epochs,trainings,HiddenNeurons)\n",
      "        mapAlgo.append((truncate,iLayers,epochs,trainings,timing,fom,HiddenNeurons))\n",
      "        print 'Samples=',truncate,'Hidden Layers=',iLayers, 'epochs=', epochs, 'trainings=', trainings, \"fom=\",fom,\" time=\", timing, 'Hidden Neurons=',HiddenNeurons \n",
      "        truncate+=10000\n",
      "    HiddenNeurons+=100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Samples= 10000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7577  time= 428.0 Hidden Neurons= 100\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7643  time= 493.0 Hidden Neurons= 100\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7627  time= 416.0 Hidden Neurons= 100\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7801  time= 432.0 Hidden Neurons= 100\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7609  time= 415.0 Hidden Neurons= 100\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7624  time= 1067.0 Hidden Neurons= 200\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7874  time= 1040.0 Hidden Neurons= 200\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7665  time= 1089.0 Hidden Neurons= 200\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7908  time= 1102.0 Hidden Neurons= 200\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7822  time= 2404.0 Hidden Neurons= 300\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7937  time= 2161.0 Hidden Neurons= 300\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.4742  time= 3719.0 Hidden Neurons= 300\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7762  time= 3112.0 Hidden Neurons= 300\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7853  time= 2682.0 Hidden Neurons= 300\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7913  time= 4240.0 Hidden Neurons= 400\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.4742  time= 5809.0 Hidden Neurons= 400\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7648  time= 5311.0 Hidden Neurons= 400\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7737  time= 3234.0 Hidden Neurons= 400\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7617  time= 3270.0 Hidden Neurons= 400\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7506  time= 5355.0 Hidden Neurons= 500\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7558  time= 5075.0 Hidden Neurons= 500\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7492  time= 4942.0 Hidden Neurons= 500\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.4742  time= 6603.0 Hidden Neurons= 500\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7707  time= 4964.0 Hidden Neurons= 500\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7501  time= 7689.0 Hidden Neurons= 600\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7499  time= 6580.0 Hidden Neurons= 600\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7496  time= 6790.0 Hidden Neurons= 600\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7698  time= 6902.0 Hidden Neurons= 600\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7697  time= 8197.0 Hidden Neurons= 600\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7508  time= 13959.0 Hidden Neurons= 700\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7678  time= 9742.0 Hidden Neurons= 700\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.7658  time= 9502.0 Hidden Neurons= 700\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.4742  time= 12456.0 Hidden Neurons= 700\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.4742  time= 10954.0 Hidden Neurons= 700\n",
        "Samples="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 Hidden Layers= 2 epochs= 10 trainings= 2 fom= 0.748  time= 11305.0 Hidden Neurons= 800\n",
        "Traceback (most recent call last):\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  File \"/usr/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 776, in structured_traceback\n",
        "    records = _fixed_getinnerframes(etb, context, tb_offset)\n",
        "  File \"/usr/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 230, in wrapped\n",
        "    return f(*args, **kwargs)\n",
        "  File \"/usr/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 259, in _fixed_getinnerframes\n",
        "    records  = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
        "  File \"/usr/local/lib/python2.7/inspect.py\", line 1044, in getinnerframes\n",
        "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
        "  File \"/usr/local/lib/python2.7/inspect.py\", line 1004, in getframeinfo\n",
        "    filename = getsourcefile(frame) or getfile(frame)\n",
        "  File \"/usr/local/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
        "    if hasattr(getmodule(object, filename), '__loader__'):\n",
        "  File \"/usr/local/lib/python2.7/inspect.py\", line 500, in getmodule\n",
        "    os.path.realpath(f)] = module.__name__\n",
        "  File \"/usr/local/lib/python2.7/posixpath.py\", line 383, in realpath\n",
        "    return abspath(path)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Internal Python error in the inspect module.\n",
        "Below is the traceback from this internal error.\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  File \"/usr/local/lib/python2.7/posixpath.py\", line 373, in abspath\n",
        "    return normpath(path)\n",
        "  File \"/usr/local/lib/python2.7/posixpath.py\", line 346, in normpath\n",
        "    path.startswith('//') and not path.startswith('///')):\n",
        "KeyboardInterrupt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Unfortunately, your original traceback can not be constructed.\n",
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": ""
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mapAlgo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}