{
 "metadata": {
  "name": "",
  "signature": "sha256:7ff4ed0878145fc4c12b443ad4fc624f591bcbd947c4699cb672dac77a28b3a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math, string, random, itertools, copy\n",
      "import numpy as np\n",
      "from numpy import float32\n",
      "from math import sqrt\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.stats import poisson\n",
      "from copy        import deepcopy\n",
      "import time\n",
      "import theanets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Couldn't import dot_parser, loading of dot files will not be possible.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import h5py\n",
      "f=h5py.File(\"data/data.hdf5\")\n",
      "f.keys()\n",
      "f['data'].keys()\n",
      "\n",
      "global input_matrix\n",
      "global target_matrix\n",
      "global decorator_matrix\n",
      "\n",
      "# Load Data \n",
      "input_matrix     = f['data']['input'].value\n",
      "target_matrix    = f['data']['target'].value\n",
      "decorator_matrix = f['data']['deco'].value\n",
      "\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nInputs  = input_matrix.shape[1]\n",
      "nOutputs = target_matrix.shape[1]\n",
      "\n",
      "print \" Inputs=\", nInputs, \"       Outputs=\",nOutputs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Inputs= 82        Outputs= 1\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def allincluded(truncate, nHiddenLayers, nHiddenNeurons):\n",
      "    \n",
      "    IN_matrix     =input_matrix[0:truncate]\n",
      "    TAR_matrix    =target_matrix[0:truncate]\n",
      "    #decorator_matrix =decorator_matrix[0:truncate]\n",
      "    \n",
      "    cut   =int(IN_matrix.shape[0]*0.8)\n",
      "    train =IN_matrix[:cut], TAR_matrix[:cut]    \n",
      "    valid =IN_matrix[cut:], TAR_matrix[cut:]\n",
      "\n",
      "    print \"Samples in Training Set=\", len(train[0])\n",
      "    print \"Samples in Validation Set=\", len(valid[0])\n",
      "    \n",
      "    # Build the NN\n",
      "    # -----------------------------------------------------------------------------------------------------------------------------------\n",
      "    # Topology: Feedforward\n",
      "    # Inputs = 82 (Jets 4-momenta (20 Jets maximum), METx, METy)\n",
      "    # Number of Hidden Layers = nHiddenLayers\n",
      "    # Activation function for Hidden Layers = RELU\n",
      "    # Outputs=1 (NN Trigger Bits= 0 or 1)\n",
      "    # Activation function for the Output Layer= RELU\n",
      "\n",
      "    exp=theanets.Experiment(theanets.feedforward.Regressor(layers=(nInputs,)+tuple([nHiddenNeurons for l in range(nHiddenLayers)])+ ( (nOutputs),)))  \n",
      "    # -----------------------------------------------------------------------------------------------------------------------------------\n",
      "    \n",
      "    timing_start = time.mktime(time.gmtime())\n",
      "\n",
      "    for i in range(3, 11):\n",
      "        LearningRate=1.0/10**(i)\n",
      "        print \"Learning Rate=\", LearningRate\n",
      "        print exp.train(train, valid, learning_rate= LearningRate, algo ='rprop', hidden_dropout= 0.5, rms_halflife= 0.995, rms_regularizer= 1e-09)\n",
      "    \n",
      "    timing_end=time.mktime(time.gmtime())\n",
      "    \n",
      "    prediction = exp.network.predict(train[0])\n",
      "    goodness = np.asarray([[cut,(list(train[1][np.where(prediction>cut)]==1).count(True)+list(train[1][np.where(prediction<cut)]==0).count(True))/ float(train[0].shape[0])]  for cut in np.arange(0,1,0.05)])   \n",
      "    fom_train = max( goodness[:,1])    \n",
      "    \n",
      "    prediction = exp.network.predict(valid[0])\n",
      "    goodness   = np.asarray([[cut,(list(valid[1][np.where(prediction>cut)]==1).count(True)+list(valid[1][np.where(prediction<cut)]==0).count(True))/ float(valid[0].shape[0])]  for cut in np.arange(0,1,0.05)])\n",
      "    fom_valid  = max( goodness[:,1])     \n",
      "\n",
      "    MaxCut= goodness[np.where(goodness[:,1]==goodness[:,1].max())][0][0]\n",
      "\n",
      "    timing=timing_end-timing_start\n",
      "    \n",
      "    #exp.save('network-pickle.pkl.gz')\n",
      "    #MaxCut=0\n",
      "    #timing=0\n",
      "    \n",
      "    return fom_valid, fom_train, MaxCut,timing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapAlgo=[]\n",
      "\n",
      "truncate=400000\n",
      "nHiddenNeurons=200\n",
      "iLayers=2\n",
      "\n",
      "print \"--------------------- iLayers = \",iLayers, \"--------------------------------------\"\n",
      "print \"   Hidden Neurons=\", nHiddenNeurons\n",
      "print \"   Samples=\",truncate\n",
      "fom_valid, fom_train, MaxCut, timing = allincluded(truncate, iLayers, nHiddenNeurons)\n",
      "print  \"   F.O.M. valid=\",fom_valid, \"FOM train=\", fom_train, \"  Time=\", timing, ' MaxCut=',MaxCut "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapAlgo.append((truncate, iLayers, nHiddenNeurons, timing, fom_valid, fom_train, MaxCut))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mapAlgo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(100000, 2, 200, 770.0, 0.88149999999999995, 0.89511249999999998, 0.5)]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "truncate=100000\n",
      "nHiddenNeurons=100\n",
      "iLayers=2\n",
      "\n",
      "print \"--------------------- iLayers = \",iLayers, \"--------------------------------------\"\n",
      "print \"   Hidden Neurons=\", nHiddenNeurons\n",
      "print \"   Samples=\",truncate\n",
      "fom_valid, fom_train, MaxCut, timing = allincluded(truncate, iLayers, nHiddenNeurons)\n",
      "print  \"   F.O.M. valid=\",fom_valid, \"FOM train=\", fom_train, \"  Time=\", timing, ' MaxCut=',MaxCut "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------- iLayers =  2 --------------------------------------\n",
        "   Hidden Neurons= 100\n",
        "   Samples= 100000\n",
        "Samples in Training Set= 80000\n",
        "Samples in Validation Set= 20000\n",
        "(OrderedDict([('loss', 0.094232830956394176), ('err', 0.094232830956394176)]), OrderedDict([('loss', 0.10264740691775055), ('err', 0.10264740691775055)]))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   F.O.M. valid="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.8742 FOM train= 0.8851375   Time= 382.0  MaxCut= 0.5\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "truncate=100000\n",
      "nHiddenNeurons=300\n",
      "iLayers=2\n",
      "\n",
      "print \"--------------------- iLayers = \",iLayers, \"--------------------------------------\"\n",
      "print \"   Hidden Neurons=\", nHiddenNeurons\n",
      "print \"   Samples=\",truncate\n",
      "fom_valid, fom_train, MaxCut, timing = allincluded(truncate, iLayers, nHiddenNeurons)\n",
      "print  \"   F.O.M. valid=\",fom_valid, \"FOM train=\", fom_train, \"  Time=\", timing, ' MaxCut=',MaxCut "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------- iLayers =  2 --------------------------------------\n",
        "   Hidden Neurons= 300\n",
        "   Samples= 100000\n",
        "Samples in Training Set= 80000\n",
        "Samples in Validation Set= 20000\n",
        "(OrderedDict([('loss', 0.086330123905885778), ('err', 0.086330123905885778)]), OrderedDict([('loss', 0.098671563710918439), ('err', 0.098671563710918439)]))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   F.O.M. valid="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.88275 FOM train= 0.8986875   Time= 1290.0  MaxCut= 0.5\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "truncate=100000\n",
      "nHiddenNeurons=400\n",
      "iLayers=2\n",
      "\n",
      "print \"--------------------- iLayers = \",iLayers, \"--------------------------------------\"\n",
      "print \"   Hidden Neurons=\", nHiddenNeurons\n",
      "print \"   Samples=\",truncate\n",
      "fom_valid, fom_train, MaxCut, timing = allincluded(truncate, iLayers, nHiddenNeurons)\n",
      "print  \"   F.O.M. valid=\",fom_valid, \"FOM train=\", fom_train, \"  Time=\", timing, ' MaxCut=',MaxCut "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------- iLayers =  2 --------------------------------------\n",
        "   Hidden Neurons= 400\n",
        "   Samples= 100000\n",
        "Samples in Training Set= 80000\n",
        "Samples in Validation Set= 20000\n",
        "(OrderedDict([('loss', 0.081679256611542655), ('err', 0.081679256611542655)]), OrderedDict([('loss', 0.096376162360000572), ('err', 0.096376162360000572)]))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   F.O.M. valid="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.88495 FOM train= 0.906   Time= 2347.0  MaxCut= 0.5\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "truncate=100000\n",
      "nHiddenNeurons=500\n",
      "iLayers=2\n",
      "\n",
      "print \"--------------------- iLayers = \",iLayers, \"--------------------------------------\"\n",
      "print \"   Hidden Neurons=\", nHiddenNeurons\n",
      "print \"   Samples=\",truncate\n",
      "fom_valid, fom_train, MaxCut, timing = allincluded(truncate, iLayers, nHiddenNeurons)\n",
      "print  \"   F.O.M. valid=\",fom_valid, \"FOM train=\", fom_train, \"  Time=\", timing, ' MaxCut=',MaxCut "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--------------------- iLayers =  2 --------------------------------------\n",
        "   Hidden Neurons= 500\n",
        "   Samples= 100000\n",
        "Samples in Training Set= 80000\n",
        "Samples in Validation Set= 20000\n",
        "(OrderedDict([('loss', 0.074107210817904584), ('err', 0.074107210817904584)]), OrderedDict([('loss', 0.092049287348726666), ('err', 0.092049287348726666)]))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "MemoryError",
       "evalue": "failed to alloc dot22 output\nApply node that caused the error: Dot22(x, hid1.w)\nInputs types: [TensorType(float64, matrix), TensorType(float64, matrix)]\nInputs shapes: [(80000, 82), (82, 500)]\nInputs strides: [(656, 8), (4000, 8)]\nInputs values: ['not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-19-f50caefab8ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"   Hidden Neurons=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnHiddenNeurons\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"   Samples=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfom_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfom_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxCut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallincluded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miLayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnHiddenNeurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m  \u001b[1;34m\"   F.O.M. valid=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfom_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FOM train=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfom_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"  Time=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiming\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' MaxCut='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMaxCut\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-7-4d745b4a5e44>\u001b[0m in \u001b[0;36mallincluded\u001b[1;34m(truncated, nHiddenLayers, nHiddenNeurons)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mtiming_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmktime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgmtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mgoodness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;32mfor\u001b[0m \u001b[0mcut\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mfom_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mgoodness\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/tmp/theanets/theanets/graph.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mvariables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         '''\n\u001b[1;32m--> 551\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/tmp/theanets/theanets/graph.pyc\u001b[0m in \u001b[0;36mfeed_forward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             )\n\u001b[0;32m    531\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m                         storage_map=self.fn.storage_map)\n\u001b[0m\u001b[0;32m    607\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m                     \u001b[1;31m# For the c linker We don't have access from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mMemoryError\u001b[0m: failed to alloc dot22 output\nApply node that caused the error: Dot22(x, hid1.w)\nInputs types: [TensorType(float64, matrix), TensorType(float64, matrix)]\nInputs shapes: [(80000, 82), (82, 500)]\nInputs strides: [(656, 8), (4000, 8)]\nInputs values: ['not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}